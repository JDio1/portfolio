# Data Engineering Portfolio

Welcome to my Data Engineering Portfolio! This repository serves as a showcase of my skills, projects, and achievements in the field of data engineering. Each project included here demonstrates my expertise in designing, building, and maintaining data pipelines, as well as my ability to leverage various technologies to solve real-world data challenges.


## Projects

### Project 1: [Expense Analysis Project](https://github.com/JDio1/expense-analysis-pipeline)
**Brief Overview:**  
The Expense Analysis Project is designed to provide a detailed examination of personal spending habits over the year 2023. Utilizing Python and powerful data analysis libraries such as Pandas, Matplotlib, and Seaborn, the project automates the process of cleaning, processing, and visualizing raw expense data. By delivering insightful statistical analyses and compelling visualizations, this project helps individuals understand their spending patterns, identify unusual expenses, and make informed financial decisions. The result is a comprehensive tool for continuous financial monitoring and optimization.

**Technology Used:**  
- Python
- Pandas
- Matplotlib
- Seaborn
- Jupyter

**Results:**  
The Expense Analysis Project transformed raw expense data into actionable insights. Key outcomes include:

- **Spending Insights**: Provided summary statistics and visual breakdowns of expenses by category.
- **Pattern Identification**: Revealed trends and variations in spending habits.
- **Outlier Detection**: Highlighted unusual spending activities.
- **Visualizations**: Created clear and informative charts and graphs.
- **Financial Insights**: Enabled better financial decisions and potential savings identification.

Overall, the project delivered a robust tool for effective personal finance management.


### Project 2: [HR Analytics and Employee Attrition Prediction](https://github.com/JDio1/employee_attrition-_prediction)
**Brief Overview:**  
The goal of this project is to analyze employee data to identify factors that contribute to employee attrition and to build predictive models to forecast which employees are likely to leave the company.

**Technology Used:**  

- **Python**: Data analysis and machine learning
- **Jupyter Notebook**: Development environment
- **Pandas, Numpy**: Data manipulation and analysis
- **Scikit-learn**: Machine learning models
- **Matplotlib, Seaborn**: Data visualization
- **Tableau Public**: Interactive dashboards and data visualization

**Results:**  

- **Exploratory Data Analysis (EDA)**: Identified key factors such as age, monthly income, and job satisfaction that correlate with employee attrition.
- **Predictive Modeling**: Developed models, including Random Forest and Logistic Regression, achieving an accuracy of 86% in predicting employee attrition.
- **Data Visualization**: Created an interactive Tableau dashboard to visualize attrition trends and key features influencing attrition.

These findings and tools provide actionable insights for HR departments to develop effective retention strategies and reduce employee turnover.


### Project 3: [Weather Data Pipeline](https://github.com/JDio1/GCP_Weather_Data_Pipeline)
**Brief Overview:**  
This project automates the collection, processing, and storage of weather data using Python and Google Cloud Platform (GCP) services. It fetches real-time weather information from the OpenWeatherMap API, processes the data, and stores it in Google Cloud Storage. The pipeline showcases modern data engineering practices, including API integration, cloud storage management, and efficient data handling using Python scripting.

**Technology Used:**  
- **Programming Language**: Python
- **Cloud Platform**: Google Cloud Platform (GCP)
- **Services**: Google Cloud Storage
- **API**: OpenWeatherMap API
- **Libraries**:
  - `google-cloud-storage`: Google Cloud Storage client library
  - `requests`: HTTP library for making API calls
  - `python-dotenv`: For loading environment variables from a `.env` file
  - `pandas`: For data manipulation and analysis
  - `db-dtypes`: For handling database-specific data types in pandas

**Results:**  
This project successfully demonstrates a complete data engineering pipeline for fetching, processing, and storing weather data. By integrating the OpenWeatherMap API with Google Cloud Platform services, the pipeline automates data collection and storage, making real-time weather information readily accessible for analysis and visualization. The project showcases effective use of Python scripting and cloud infrastructure to handle and manage data efficiently.

### Project 4: [PowerBI Survey Analysis](https://github.com/JDio1/Power_BI_Survey_Analysis)
**Brief Overview:**  
This project aims to analyze a survey dataset collected from data professionals to derive meaningful insights. Using Power BI, the dataset was cleaned, transformed, and visualized, addressing issues such as missing values and inconsistent data types.

**Technology Used:**  
- Power BI

**Results:**  
The project resulted in a user-friendly Power BI dashboard that provides clear, actionable insights into the preferences, experiences, and challenges faced by data professionals. This dashboard aids in better decision-making and strategic planning based on survey responses.

### Project 5: [PowerBI Performance Report](https://github.com/JDio1/Power_BI_Performance_Report)
**Brief Overview:**  
This project shows the performamnce report of Plant Co. in terms of Gross Profit, Sales, and Quanty in different countries in 2023 to 2024.
**Technology Used:**  
- Power BI

**Results:**  
The project resulted in a user-friendly Power BI dashboard that provides a condensed, dynamic performance report that utilises SWITCH measures and conditional formatting.

### Project 6: [Iris Predictor Cloud Function & Machine Learning](https://github.com/JDio1/Iris_Predictor)
**Brief Overview:**  
The Iris Predictor Cloud Function is a serverless machine learning service that predicts the species of an iris flower based on its sepal and petal dimensions. Utilizing Google Cloud Functions and a pre-trained Scikit-learn model, this project demonstrates the seamless integration of machine learning into a scalable, serverless environment. It provides a RESTful API endpoint for real-time predictions, showcasing efficient deployment of ML models without the need for managing infrastructure.

**Technology Used:**  
- Python
- Google Colab
- Google Cloud Functions
- Scikit-learn (for machine learning model)
- MLflow

**Results:**  
The Cloud Function returns predictions for the species of iris flower based on the input dimensions, demonstrating the integration of machine learning into serverless environments.

## Contact
Feel free to reach out to me for any questions or collaboration opportunities:
- **Email:** justinutodio@gmail.com
- **LinkedIn:** [Justin Uto-Dieu](https://linkedin.com/in/justin-uto-dieu)